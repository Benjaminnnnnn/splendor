Hey, can you sketch a TypeScript/Express “AI advisor” backend for Splendor? Think human-friendly: build a tiny OpenAIProvider wrapper around chat completions (gpt-4o), pull OPENAI_API_KEY from env, strip ``` fences, and reject any non-JSON payload. The AIService should accept (gameId, playerId), ask GameService for state, and return a JSON string like {action: "take_tokens" | "purchase_card" | "reserve_card" | "purchase_reserved_card" | "wait", reasoning, details?: {tokens?: GemCounts, cardId?: string, payment?: GemCounts}, confidenceScore}. Before returning, enforce rules yourself: block taking tokens when player has >=10, max 3 tokens/turn, only 3 distinct singles OR exactly 2 of one color, never exceed the 10-token cap, no reserve if already 3 reserved. If it’s not their turn, reply with action "wait" and a confident explanation.

Please craft the actual LLM prompt string we’ll send: summarize the game (current player tokens/bonuses/reserved cards, board cards per tier, nobles, token bank, opponents), list Splendor constraints (token-taking patterns, 10-token limit, 3-reserve limit, 15 prestige to win), and demand JSON only with diamond/sapphire/emerald/ruby/onyx/gold keys, omitting null/undefined fields.

Wire up Express at GET /api/ai/:gameId/recommendation?playerId=... with a controller/service split. Instantiate AIService, call getGameRecommendation, and respond { recommendation }. Return 400 for missing playerId and 500 on server errors.

On the frontend, add an aiService client hitting GET /api/ai/:gameId/recommendation with playerId. In GamePage, when state === IN_PROGRESS and it’s your turn, fetch once per turn, show a loading shimmer, and pass the raw string to GameBoard. In GameBoard, defensively parse JSON (strip ```json), render an action badge, reasoning, token/card/payment details, and confidence; on parse failure, show a fallback. Hide the panel if it’s not your turn.

Read the existing unit, integration, property-based, and e2e tests around the AI advisor (validator + controller). What edge cases are missing? Please add edge-focused tests only: unit cases like player already at 10 tokens but model says take_tokens; model tries 2 same + 1 different; model tries 4 tokens; model tries 2 different singles; model’s take pushes total over 10; model reserves when 3 reserved; not-their-turn should get "wait". Integration/e2e: malformed JSON from OpenAI, missing playerId returns 400, upstream GameService errors bubble as 500. Property-ish: random token distributions never allow >3 tokens or invalid patterns. Use mocked GameService/OpenAIProvider and keep the scope tight to these gaps.
